{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "234ecfc9",
   "metadata": {},
   "source": [
    "https://blog.roboflow.com/how-to-use-yolov8-with-sam/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d4aff4",
   "metadata": {},
   "source": [
    "# Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfcd9e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.200  Python-3.9.18 torch-2.0.0 CUDA:0 (NVIDIA RTX A4500, 20470MiB)\n",
      "Setup complete  (128 CPUs, 255.9 GB RAM, 252.0/953.3 GB disk)\n",
      "ERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/segment-anything.git'\"\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from IPython.display import display, Image\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the device for GPU acceleration\n",
    "device = \"cuda\"\n",
    "\n",
    "# Check Ultralytics version and setup completion\n",
    "ultralytics.checks()\n",
    "\n",
    "# Set the first_run flag to False after the initial run\n",
    "first_run = True\n",
    "\n",
    "if first_run:\n",
    "    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eecd39",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bffaa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'roboflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mroboflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Roboflow\n\u001b[0;32m      2\u001b[0m rf \u001b[38;5;241m=\u001b[39m Roboflow(api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYOUR_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m project \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mworkspace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvkr-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mproject(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvkrrr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'roboflow'"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"YOUR_API_KEY\")\n",
    "project = rf.workspace(\"vkr-v2\").project(\"vkrrr\")\n",
    "dataset = project.version(5).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5055b87f",
   "metadata": {},
   "source": [
    "# Running YOLOv8 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe08e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\WANGH0M\\gaussian-splatting\\data_bonsai_new\\images\\IMG_6056.png: 640x480 1 potted plant, 1 dining table, 1 vase, 89.3ms\n",
      "Speed: 5.0ms preprocess, 89.3ms inference, 24.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "path = r'C:\\Users\\WANGH0M\\gaussian-splatting\\data_bonsai_new\\images'\n",
    "name = path + r'\\IMG_6056.png'\n",
    "# Perform object detection on the image\n",
    "results = model.predict(source=name, conf=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49cfc9",
   "metadata": {},
   "source": [
    "# Extracting the Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02bd1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[587.7847900390625, 1084.9083251953125, 1065.2694091796875, 1613.078857421875]\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "bbox = boxes.xyxy.tolist()[0]\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c87b5",
   "metadata": {},
   "source": [
    "# Convert Bounding Box to Segmentation Mask using SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f61e48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segment_anything'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegment_anything\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n\u001b[0;32m      3\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(name), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m      4\u001b[0m sam_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msam_vit_h_4b8939.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'segment_anything'"
     ]
    }
   ],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB)\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)\n",
    "predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6caa2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d63fe1",
   "metadata": {},
   "source": [
    "## Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "803657bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_box \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(bbox)\n\u001b[1;32m----> 2\u001b[0m masks, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[0;32m      3\u001b[0m     point_coords\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     point_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m     box\u001b[38;5;241m=\u001b[39mbbox[\u001b[38;5;28;01mNone\u001b[39;00m, :],\n\u001b[0;32m      6\u001b[0m     multimask_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "input_box = np.array(bbox)\n",
    "masks, _, _ = predictor.predict(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=bbox[None, :],\n",
    "    multimask_output=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e52142",
   "metadata": {},
   "source": [
    "## Plot mask + Bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f33f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "show_mask(masks[0], plt.gca())\n",
    "show_box(input_box, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b63114",
   "metadata": {},
   "source": [
    "# Background Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_mask = masks[0]\n",
    "\n",
    "# Convert the segmentation mask to a binary mask\n",
    "binary_mask = np.where(segmentation_mask > 0.5, 1, 0)\n",
    "white_background = np.ones_like(image) * 255\n",
    "\n",
    "# Apply the binary mask\n",
    "new_image = white_background * (1 - binary_mask[..., np.newaxis]) + image * binary_mask[..., np.newaxis]\n",
    "\n",
    "plt.imshow(new_image.astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca84d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
